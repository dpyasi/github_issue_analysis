# ðŸš€ **Execution Guide - Step by Step**

## **For New Users Opening Your GitHub Repository**

### **ðŸ“‹ Prerequisites Checklist**
- [ ] Databricks workspace access
- [ ] Python environment with required packages
- [ ] GitHub Personal Access Token (optional but recommended)
- [ ] Basic understanding of Spark/Delta Lake

### **ðŸŽ¯ Execution Order (What to Run First)**

## **Step 1: Database Setup** 
```sql
-- Run this FIRST in Databricks SQL or notebook
%run /path/to/sql/create_tables.sql
```
**What it does**: Creates the target table structure for your data
**Expected result**: Table `loungebip_test.internal.huggingface_transformers_issues` created

---

## **Step 2: ETL Pipeline (Main Data Loading)**
```python
# Run this SECOND in Databricks notebook
%run /path/to/etl/github_issues_etl_databricks.py
```
**What it does**: 
- Fetches GitHub issues data via API
- Transforms data with proper schema
- Loads data into Delta Lake table
- Handles 10,000+ issues with authentication

**Expected result**: 
- 10,000+ records loaded into your table
- Logs showing successful data loading
- Data ready for analysis

---

## **Step 3: Generate Static Charts (Optional)**
```python
# Run these THIRD for static visualizations
%run /path/to/create_funnel_chart.py
%run /path/to/create_monthly_trends_2024.py
%run /path/to/create_simple_labels_chart.py
%run /path/to/create_long_open_issues_chart.py
```
**What it does**: Creates 25+ professional charts in PNG format
**Expected result**: Charts saved in respective folders

---

## **Step 4: Interactive Dashboard (Recommended)**
```bash
# Run this FOURTH for interactive analysis
streamlit run visualizations/github_issues_dashboard.py
```
**What it does**: 
- Launches interactive Streamlit dashboard
- Real-time data visualization
- Funnel charts, trends, labels analysis
- Interactive exploration of your data

**Expected result**: 
- Dashboard opens in browser
- Interactive charts and metrics
- Real-time data exploration

---

## **ðŸ”„ Regular Updates (After Initial Setup)**

### **Daily/Weekly Updates:**
```python
# Just run the ETL pipeline to get latest data
%run /path/to/etl/github_issues_etl_databricks.py
```

### **Generate Updated Charts:**
```python
# Run chart scripts to update visualizations
%run /path/to/create_*.py
```

---

## **ðŸ“Š What Each Step Produces**

### **Step 1 Output:**
- âœ… Database table structure created
- âœ… Schema optimized for analytics
- âœ… ETL logging table ready

### **Step 2 Output:**
- âœ… 10,000+ GitHub issues loaded
- âœ… Complete dataset with all fields
- âœ… Data ready for analysis
- âœ… Logs showing success/failure

### **Step 3 Output:**
- âœ… 25+ professional charts
- âœ… Funnel analysis
- âœ… Monthly trends
- âœ… Labels analysis
- âœ… Long-open issues analysis

### **Step 4 Output:**
- âœ… Interactive dashboard
- âœ… Real-time data exploration
- âœ… Interactive charts
- âœ… Summary metrics
- âœ… Data filtering capabilities

---

## **ðŸŽ¯ Quick Start (5 Minutes)**

### **Minimum Viable Setup:**
1. **Database**: Run `sql/create_tables.sql`
2. **ETL**: Run `etl/github_issues_etl_databricks.py`
3. **Dashboard**: Run `streamlit run visualizations/github_issues_dashboard.py`

### **Expected Timeline:**
- **Database Setup**: 30 seconds
- **ETL Pipeline**: 5-10 minutes (depending on data volume)
- **Dashboard**: 30 seconds to launch

---

## **ðŸ”§ Configuration Required**

### **Before Running ETL:**
```python
# Update these in github_issues_etl_databricks.py
REPO_OWNER = "your_org"           # Change to your GitHub org
REPO_NAME = "your_repo"           # Change to your repository
GITHUB_TOKEN = "your_token"       # Add your GitHub token
```

### **Before Running Dashboard:**
```python
# Update table name in github_issues_dashboard.py
table_name = "your_schema.your_table"  # Change to your table
```

---

## **ðŸ“ˆ Success Indicators**

### **ETL Success:**
- âœ… "Successfully loaded X records to table"
- âœ… No error messages in logs
- âœ… Data visible in table

### **Dashboard Success:**
- âœ… Dashboard opens in browser
- âœ… Charts display correctly
- âœ… Data loads without errors

### **Charts Success:**
- âœ… PNG files generated in folders
- âœ… No error messages during generation
- âœ… Charts display properly

---

## **ðŸš¨ Common Issues & Solutions**

### **Issue: "Table not found"**
**Solution**: Run Step 1 (Database Setup) first

### **Issue: "Rate limit exceeded"**
**Solution**: Add GitHub token to ETL script

### **Issue: "Schema errors"**
**Solution**: Check data types in ETL script

### **Issue: "Dashboard won't start"**
**Solution**: Install Streamlit: `pip install streamlit`

---

## **ðŸŽ¯ Final Result**

After completing all steps, you'll have:
- âœ… **Complete GitHub issues dataset** in Delta Lake
- âœ… **Interactive dashboard** for data exploration
- âœ… **25+ professional charts** for analysis
- âœ… **ETL pipeline** for regular updates
- âœ… **Full documentation** for team use

**Your GitHub repository will be a complete, professional analytics toolkit!** ðŸš€
